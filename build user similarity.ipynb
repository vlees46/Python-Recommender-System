{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a10458-afa2-437a-a7ef-d1e516ef93bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your user-user system should take as input a particular user ID and return a set of top 5 most similar users. For each of the similar users, \n",
    "# also retrieve their top rated books from the sampled dataset. Perform similar hyperparameter testing as in Problem 2 and detail your experiences using each system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "73ed2d3f-2675-403f-a551-aa812199d731",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving metadata\n",
      "Users: 15\n",
      "Books: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2476it [00:00, 51555.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 4. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 5. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 5. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 5.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] This is the RATING Matrix\n",
      "Converting to sparse\n",
      "Computing similarity\n",
      "[[0.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.        ]\n",
      " [1.         0.         0.11404202 1.         1.         1.99933763\n",
      "  1.         1.         1.         1.         1.         1.93680043\n",
      "  1.         0.82315132]\n",
      " [1.         0.11404202 0.         1.         1.         1.86849423\n",
      "  1.         1.         1.         1.         1.         1.66771087\n",
      "  1.         0.38686383]\n",
      " [1.         1.         1.         0.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.        ]\n",
      " [1.         1.         1.         1.         0.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.        ]\n",
      " [1.         1.99933763 1.86849423 1.         1.         0.\n",
      "  1.         1.         1.         1.         1.         0.05108816\n",
      "  1.         1.14091409]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  0.         1.         1.         1.         1.         1.\n",
      "  1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         0.         1.         1.         1.         1.\n",
      "  1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         0.         1.         1.         1.\n",
      "  1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         0.         1.         1.\n",
      "  1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         0.         1.\n",
      "  1.         1.        ]\n",
      " [1.         1.93680043 1.66771087 1.         1.         0.05108816\n",
      "  1.         1.         1.         1.         1.         0.\n",
      "  1.         0.82132227]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  0.         1.        ]\n",
      " [1.         0.82315132 0.38686383 1.         1.         1.14091409\n",
      "  1.         1.         1.         1.         1.         0.82132227\n",
      "  1.         0.        ]] This is the Generate similarity\n",
      "Saving similarity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "##Script to build book recommendation systems.\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from tqdm import tqdm\n",
    "\n",
    "def read_raw_data(_num_samples, _fn):\n",
    "    _df = pd.read_csv(\"goodreads_interactions.csv\", nrows=_num_samples)\n",
    "    _df = _df[_df.is_read == 1]\n",
    "    _df = _df[0:_num_samples]  \n",
    "    _df.to_csv('goodreads_{}.csv'.format(_fn, index=False))\n",
    " #   return _df  # Return the dataframe for further use\n",
    "\n",
    "\n",
    "def build_rating_matrix(_df):\n",
    "    \n",
    "    _n_users = len(_df.user_id.unique()) + 1  # python indices start at zero, user_ids start at 1\n",
    "    _n_books = _df.book_idx.max() + 1  # python indices start at zero, book_ids start at 1\n",
    "    print('Users: {}'.format(_n_users))\n",
    "    print('Books: {}'.format(_n_books))\n",
    "    _ratings = np.zeros((_n_users, _n_books))\n",
    "    for _, row in tqdm(_df.iterrows()):\n",
    "        i = row.user_id\n",
    "        j = row.book_idx\n",
    "        _ratings[i, j] = row.rating\n",
    "    #print(_ratings, 'THis is the rating Matrix')\n",
    "    return _ratings\n",
    "\n",
    "def recommend_user_similarity(_matrix, _eps, _n_latent):\n",
    "    \n",
    "  #  _user_svd = TruncatedSVD(n_components=min(_matrix.shape)-1)  # Adjust to prevent dimension issues\n",
    "    _user_svd = TruncatedSVD(n_components=_n_latent)    \n",
    "    _user_features = _user_svd.fit_transform(_matrix.transpose())    \n",
    "    \n",
    "    print('Converting to sparse')\n",
    "    \n",
    "    _user_similarity = sparse.csr_matrix(_user_features)\n",
    "    return _user_similarity\n",
    "\n",
    "\n",
    "def generate_similarity_matrix(_features, _metric):\n",
    "    \"\"\"\n",
    "    Generates the similarity matrix from either item or user features\n",
    "    based on the given similarity metric.\n",
    "    :param _features: The matrix of user or item features.\n",
    "    :param _metric: A string indicating which similarity metric should be used.\n",
    "    :return: _similarity_matrix, The final similarity matrix.\n",
    "    \"\"\"\n",
    "    assert _metric in ['cityblock', 'cosine', 'euclidean', 'l1', 'l2', 'manhattan']\n",
    "    print('Computing similarity')\n",
    "    _similarity_matrix = pairwise_distances(_features, metric=_metric)\n",
    "    return _similarity_matrix\n",
    "\n",
    "def merge_meta(_meta_path, _map_path, _ratings):\n",
    "    \"\"\"\n",
    "    Merges book metadata with ratings.\n",
    "\n",
    "    :param _meta_path: Path to book metadata csv.\n",
    "    :param _map_path: Path to book ID mapping.\n",
    "    :param _ratings: Dataframe of rating interactions.\n",
    "    :return: _ratings_meta, a dataframe of metadata and ratings and\n",
    "    _metadata_lookup, dictionary for the UI.\n",
    "    \"\"\"\n",
    "    _meta = pd.read_csv(_meta_path)\n",
    "    _map = pd.read_csv(_map_path)\n",
    "    _ratings_map = _ratings.merge(_map, how='left',\n",
    "                                  left_on='user_id', right_on='book_id_csv')\n",
    "    _ratings_map = _ratings_map[['user_id', 'book_id_csv', 'is_read',\n",
    "                                 'rating', 'is_reviewed', 'book_id_y']]\n",
    "    _ratings_map.columns = ['user_id', 'book_idx', 'is_read',\n",
    "                            'rating', 'is_reviewed', 'book_id']\n",
    "    _metadata_lookup = {}\n",
    "    for _, row in _ratings_map.iterrows():\n",
    "        _md = _meta[_meta['book_id'] == row['book_id']]\n",
    "        _metadata_lookup[str(row.user_id)] = {\n",
    "            'title': _md['title'].values[0],\n",
    "            'link': _md['link'].values[0]}\n",
    "        \n",
    "    #print(_ratings_map, ' THis is the Rating MAP')\n",
    "    #print(_metadata_lookup, 'This is the metadata lookup')\n",
    "    return _ratings_map, _metadata_lookup\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    NS = 9000\n",
    "    FN = '9k'\n",
    "    EPS = 1e-9\n",
    "    FACTORS = 2\n",
    "    METRIC = 'cosine'\n",
    "\n",
    "    try:\n",
    "        goodreads = pd.read_csv('goodreads_{}.csv'.format(FN))\n",
    "        #print(goodreads)\n",
    "    except FileNotFoundError:\n",
    "        read_raw_data(NS, FN)\n",
    "        goodreads = pd.read_csv('goodreads_{}.csv'.format(FN))\n",
    "\n",
    "\n",
    "    ratings_meta, metadata_lookup = merge_meta(\n",
    "        'book_metadata.csv',\n",
    "        'book_id_map.csv', goodreads)\n",
    "    \n",
    "    print('Saving metadata')\n",
    "    \n",
    "\n",
    "   # print('This is the meataData',  ratings_meta)\n",
    "   # print(' THis is the metadata lookup', metadata_lookup)\n",
    "    \n",
    "    with open('books_metadata_{records}.json'.format(records=FN), 'w', encoding='utf-8') as m:\n",
    "        json.dump(metadata_lookup, m)\n",
    "    \n",
    "    ratings = build_rating_matrix(ratings_meta)\n",
    "    \n",
    "    print(ratings,  'This is the RATING Matrix')\n",
    "    \n",
    "    user_similarity = recommend_user_similarity(ratings, EPS, FACTORS)  # Calculating user-user similarity\n",
    "    \n",
    "    #print(user_similarity,  'This is the Recommender Similarity')\n",
    "    \n",
    "    sim = generate_similarity_matrix(user_similarity, METRIC)\n",
    "\n",
    "    print(sim, 'This is the Generate similarity')\n",
    "    \n",
    "    #with open('user_similarity_{FACTORS}_{FN}_{METRIC}.pkl', 'wb') as f:\n",
    "        #pickle.dump(user_similarity, f)\n",
    "    print('Saving similarity')\n",
    "    \n",
    "    with open('user_similarity_{factors}_{records}_{metric}.pkl'.format(factors=FACTORS,\n",
    "                                                                        records=FN,\n",
    "                                                                        metric=METRIC), 'wb') as f:\n",
    "        pickle.dump(sim, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f33223d-f39e-48f8-88c6-ddfd8cc38fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
